{
  "swagger": "2.0",
  "info": {
    "version": "1.0",
    "title": "Face Client",
    "description": "An API for face detection, verification, and identification."
  },
  "paths": {
    "/findsimilars": {
      "post": {
        "description": "Given query face's faceId, to search the similar-looking faces from a faceId array, a face list or a large face list. faceId array contains the faces created by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), which will expire 24 hours after creation. A \"faceListId\" is created by [FaceList - Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/create) containing persistedFaceIds that will not expire. And a \"largeFaceListId\" is created by [LargeFaceList - Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/create) containing persistedFaceIds that will also not expire. Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.\n<br/>Find similar has two working modes, \"matchPerson\" and \"matchFace\". \"matchPerson\" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. \"matchFace\" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.\n<br/>The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.\n",
        "operationId": "Face_FindSimilar",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "body",
            "name": "body",
            "description": "Request body for Find Similar.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/FindSimilarRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of the most similar faces represented in faceId if the input parameter is faceIds or persistedFaceId if the input parameter is faceListId.",
            "schema": {
              "$ref": "#/definitions/SimilarFaces"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Find similar results example": {
            "$ref": "./examples/FindSimilar.json"
          }
        }
      }
    },
    "/group": {
      "post": {
        "description": "Divide candidate faces into groups based on face similarity.<br />\n* The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result.\n* MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts.\n* Group API needs at least 2 candidate faces and 1000 at most. We suggest to try [Face - Verify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface) when you only have 2 candidate faces.\n* The 'recognitionModel' associated with the query faces' faceIds should be the same.\n",
        "operationId": "Face_Group",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "body",
            "name": "body",
            "description": "Request body for grouping.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/GroupRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns one or more groups of similar faces (rank by group size) and a messyGroup.",
            "schema": {
              "$ref": "#/definitions/GroupResult"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Group example": {
            "$ref": "./examples/Group.json"
          }
        }
      }
    },
    "/identify": {
      "post": {
        "description": "1-to-many identification to find the closest matches of the specific query person face from a person group or large person group.\n<br/> For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in [PersonGroup - Train](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/train) and [LargePersonGroup - Train](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/train).\n<br/>\n \nRemarks:<br />\n* The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.\n* Each person in the person group/large person group could have more than one face, but no more than 248 faces.\n* Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.\n* Try [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar) when you need to find similar faces from a face list/large face list instead of a person group/large person group.\n* The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.\n",
        "operationId": "Face_Identify",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "body",
            "name": "body",
            "description": "Request body for identify operation.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/IdentifyRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the identified candidate person(s) for each query face.",
            "schema": {
              "$ref": "#/definitions/IdentifyResults"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Identify example": {
            "$ref": "./examples/Identify.json"
          }
        }
      }
    },
    "/verify": {
      "post": {
        "description": "Verify whether two faces belong to a same person or whether one face belongs to a person.\n<br/>\nRemarks:<br />\n* Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* For the scenarios that are sensitive to accuracy please make your own judgment.\n* The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.\n",
        "operationId": "Face_VerifyFaceToFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "body",
            "name": "body",
            "description": "Request body for face to face verification.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/VerifyFaceToFaceRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the verification result.",
            "schema": {
              "$ref": "#/definitions/VerifyResult"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Verify faces example": {
            "$ref": "./examples/VerifyFaceToFace.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/persons": {
      "post": {
        "description": "Create a new person in a specified person group.",
        "operationId": "PersonGroupPerson_Create",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for creating new person.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns a new personId created.",
            "schema": {
              "$ref": "#/definitions/Person"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create new person for person group example": {
            "$ref": "./examples/CreateNewPersonGroupPerson.json"
          }
        }
      },
      "get": {
        "description": "List all persons in a person group, and retrieve person information (including personId, name, userData and persistedFaceIds of registered faces of the person).",
        "operationId": "PersonGroupPerson_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "in": "query",
            "name": "start",
            "description": "Starting person id to return (used to list a range of persons).",
            "required": false,
            "type": "string"
          },
          {
            "in": "query",
            "name": "top",
            "description": "Number of persons to return starting with the person id indicated by the 'start' parameter.",
            "required": false,
            "type": "integer",
            "maximum": 1000,
            "minimum": 1
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of person information that belong to the person group.",
            "schema": {
              "$ref": "#/definitions/Persons"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List persons in person group": {
            "$ref": "./examples/ListPersonGroupPersons.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/persons/{personId}": {
      "delete": {
        "description": "Delete an existing person from a person group. The persistedFaceId, userData, person name and face feature in the person entry will all be deleted.",
        "operationId": "PersonGroupPerson_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete an existing person example": {
            "$ref": "./examples/DeletePersonGroupPerson.json"
          }
        }
      },
      "get": {
        "description": "Retrieve a person's information, including registered persisted faces, name and userData.",
        "operationId": "PersonGroupPerson_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the person's information.",
            "schema": {
              "$ref": "#/definitions/Person"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get person example": {
            "$ref": "./examples/GetPersonGroupPerson.json"
          }
        }
      },
      "patch": {
        "description": "Update name or userData of a person.",
        "operationId": "PersonGroupPerson_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for person update operation.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update person example": {
            "$ref": "./examples/UpdatePersonGroupPerson.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/persons/{personId}/persistedfaces/{persistedFaceId}": {
      "delete": {
        "description": "Delete a face from a person in a person group by specified personGroupId, personId and persistedFaceId.\n<br /> Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.",
        "operationId": "PersonGroupPerson_DeleteFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete face from person example": {
            "$ref": "./examples/DeletePersonGroupPersonFace.json"
          }
        }
      },
      "get": {
        "description": "Retrieve information about a persisted face (specified by persistedFaceId, personId and its belonging personGroupId).",
        "operationId": "PersonGroupPerson_GetFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns target persisted face's information (persistedFaceId and userData).",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get persisted face example": {
            "$ref": "./examples/GetPersonGroupPersistedFace.json"
          }
        }
      },
      "patch": {
        "description": "Add a face to a person into a person group for face identification or verification. To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [PersonGroup PersonFace - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/deleteface), [PersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/delete) or [PersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.",
        "operationId": "PersonGroupPerson_UpdateFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating persisted face.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/UpdateFaceRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update person face example": {
            "$ref": "./examples/UpdatePersonGroupPersonFace.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}": {
      "put": {
        "description": "Create a new person group with specified personGroupId, name, user-provided userData and recognitionModel.\n<br /> A person group is the container of the uploaded person data, including face recognition features.\n<br /> After creation, use [PersonGroup Person - Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/create) to add persons into the group, and then call [PersonGroup - Train](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/train) to get this group ready for [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify).\n<br /> No image will be stored. Only the person's extracted face features and userData will be stored on server until [PersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/delete) or [PersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/delete) is called.\n<br/>'recognitionModel' should be specified to associate with this person group. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing person group will use the recognition model that's already associated with the collection. Existing face features in a person group can't be updated to features extracted by another version of recognition model.\n* 'recognition_01': The default recognition model for [PersonGroup - Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/create). All those person groups created before 2019 March are bonded with this recognition model.\n* 'recognition_02': Recognition model released in 2019 March.\n* 'recognition_03': Recognition model released in 2020 May. 'recognition_03' is recommended since its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.\n\nPerson group quota:\n* Free-tier subscription quota: 1,000 person groups. Each holds up to 1,000 persons.\n* S0-tier subscription quota: 1,000,000 person groups. Each holds up to 10,000 persons.\n* to handle larger scale face identification problem, please consider using [LargePersonGroup](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup).",
        "operationId": "PersonGroup_Create",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for creating new person group.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/MetaDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create new person group example": {
            "$ref": "./examples/CreateNewPersonGroup.json"
          }
        }
      },
      "delete": {
        "description": "Delete an existing person group. Persisted face features of all people in the person group will also be deleted.",
        "operationId": "PersonGroup_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete a person group example": {
            "$ref": "./examples/DeletePersonGroup.json"
          }
        }
      },
      "get": {
        "description": "Retrieve person group name, userData and recognitionModel. To get person information under this personGroup, use [PersonGroup Person - List](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/list).",
        "operationId": "PersonGroup_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the person group's information.",
            "schema": {
              "$ref": "#/definitions/PersonGroup"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get person group example": {
            "$ref": "./examples/GetPersonGroup.json"
          }
        }
      },
      "patch": {
        "description": "Update an existing person group's display name and userData. The properties which does not appear in request body will not be updated.",
        "operationId": "PersonGroup_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating person group.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update person group example": {
            "$ref": "./examples/UpdatePersonGroup.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/training": {
      "get": {
        "description": "Retrieve the training status of a person group (completed or ongoing).",
        "operationId": "PersonGroup_GetTrainingStatus",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the person group's training status.",
            "schema": {
              "$ref": "#/definitions/TrainingStatus"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get person group's training status example": {
            "$ref": "./examples/GetPersonGroupTrainingStatus.json"
          }
        }
      }
    },
    "/persongroups": {
      "get": {
        "description": "List person groups’ personGroupId, name, userData and recognitionModel.<br />\n* Person groups are stored in alphabetical order of personGroupId.\n* \"start\" parameter (string, optional) is a user-provided personGroupId value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry’s Id of the current call.\n<br />\nFor example, total 5 person groups: \"group1\", ..., \"group5\".\n<br /> \"start=&top=\" will return all 5 groups.\n<br /> \"start=&top=2\" will return \"group1\", \"group2\".\n<br /> \"start=group2&top=3\" will return \"group3\", \"group4\", \"group5\".\n",
        "operationId": "PersonGroup_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "query",
            "name": "start",
            "description": "List person groups from the least personGroupId greater than the \"start\".",
            "required": false,
            "type": "string",
            "maxLength": 64
          },
          {
            "in": "query",
            "name": "top",
            "description": "The number of person groups to list.",
            "required": false,
            "type": "integer",
            "default": 1000,
            "maximum": 1000,
            "minimum": 1
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of person groups and their information.",
            "schema": {
              "$ref": "#/definitions/PersonGroups"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List person groups example": {
            "$ref": "./examples/ListPersonGroups.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/train": {
      "post": {
        "description": "Queue a person group training task, the training task may not be started immediately.",
        "operationId": "PersonGroup_Train",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          }
        ],
        "responses": {
          "202": {
            "description": "The training task was queued successfully."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Queue person group training": {
            "$ref": "./examples/QueuePersonGroupTraining.json"
          }
        }
      }
    },
    "/facelists/{faceListId}": {
      "put": {
        "description": "Create an empty face list with user-specified faceListId, name, an optional userData and recognitionModel. Up to 64 face lists are allowed in one subscription.\n<br /> Face list is a list of faces, up to 1,000 faces, and used by [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar).\n<br /> After creation, user should use [FaceList - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/addfacefromurl) to import the faces. No image will be stored. Only the extracted face features are stored on server until [FaceList - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/delete) is called.\n<br /> Find Similar is used for scenario like finding celebrity-like faces, similar face filtering, or as a light way face identification. But if the actual use is to identify person, please use [PersonGroup](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup) / [LargePersonGroup](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup) and [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify).\n<br /> Please consider [LargeFaceList](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist) when the face number is large. It can support up to 1,000,000 faces.\n<br />'recognitionModel' should be specified to associate with this face list. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing face list will use the recognition model that's already associated with the collection. Existing face features in a face list can't be updated to features extracted by another version of recognition model.\n* 'recognition_01': The default recognition model for [FaceList- Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/create). All those face lists created before 2019 March are bonded with this recognition model.\n* 'recognition_02': Recognition model released in 2019 March.\n* 'recognition_03': Recognition model released in 2020 May. 'recognition_03' is recommended since its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.",
        "operationId": "FaceList_Create",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for creating a face list.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/MetaDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create new face list example": {
            "$ref": "./examples/CreateNewFaceList.json"
          }
        }
      },
      "get": {
        "description": "Retrieve a face list’s faceListId, name, userData, recognitionModel and faces in the face list.\n",
        "operationId": "FaceList_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the face list's information.",
            "schema": {
              "$ref": "#/definitions/FaceList"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get Face list example": {
            "$ref": "./examples/GetFaceList.json"
          }
        }
      },
      "patch": {
        "description": "Update information of a face list.",
        "operationId": "FaceList_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating a face list.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update face list example": {
            "$ref": "./examples/UpdateFaceList.json"
          }
        }
      },
      "delete": {
        "description": "Delete a specified face list.",
        "operationId": "FaceList_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete face list example": {
            "$ref": "./examples/DeleteFaceList.json"
          }
        }
      }
    },
    "/facelists": {
      "get": {
        "description": "List face lists’ faceListId, name, userData and recognitionModel. <br /> \nTo get face information inside faceList use [FaceList - Get](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/get)\n",
        "operationId": "FaceList_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of faceList.",
            "schema": {
              "$ref": "#/definitions/FaceLists"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List Face lists example": {
            "$ref": "./examples/ListFaceLists.json"
          }
        }
      }
    },
    "/facelists/{faceListId}/persistedfaces/{persistedFaceId}": {
      "delete": {
        "description": "Delete a face from a face list by specified faceListId and persistedFaceId.\n<br /> Adding/deleting faces to/from a same face list are processed sequentially and to/from different face lists are in parallel.",
        "operationId": "FaceList_DeleteFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete face in face list example": {
            "$ref": "./examples/DeleteFaceListFace.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/persons/{personId}/persistedfaces": {
      "post": {
        "description": "Add a face to a person into a person group for face identification or verification. To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [PersonGroup PersonFace - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/deleteface), [PersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/delete) or [PersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n*   Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n*   Each person entry can hold up to 248 faces.\n*   JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n*   \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n*   Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n*   Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [PersonGroup Person - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |",
        "operationId": "PersonGroupPerson_AddFaceFromUrl",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "$ref": "#/parameters/detectionModel"
          },
          {
            "in": "body",
            "name": "ImageUrl",
            "description": "A JSON document with a URL pointing to the image that is to be analyzed.",
            "required": true,
            "x-ms-parameter-location": "method",
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/ImageUrl"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Add Person face example": {
            "$ref": "./examples/AddPersonGroupPersonFaceFromUrl.json"
          }
        }
      }
    },
    "/detect": {
      "post": {
        "description": "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.<br />\n* No image will be stored. Only the extracted face feature will be stored on server. The faceId is an identifier of the face feature and will be used in [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify), [Face - Verify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface), and [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar). The stored face feature(s) will expire and be deleted 24 hours after the original detection call.\n* Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\n* For optimal results when querying [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify), [Face - Verify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface), and [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar) ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |\n\n* Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to [How to specify a recognition model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'recognition_01': | The default recognition model for [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl). All those faceIds created before 2019 March are bonded with this recognition model. |\n  | 'recognition_02': | Recognition model released in 2019 March. |\n  | 'recognition_03': | Recognition model released in 2020 May. 'recognition_03' is recommended since its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. |",
        "operationId": "Face_DetectWithUrl",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "query",
            "name": "returnFaceId",
            "description": "A value indicating whether the operation should return faceIds of detected faces.",
            "type": "boolean",
            "default": true
          },
          {
            "in": "query",
            "name": "returnFaceLandmarks",
            "description": "A value indicating whether the operation should return landmarks of the detected faces.",
            "type": "boolean",
            "default": false
          },
          {
            "$ref": "#/parameters/returnFaceAttributes"
          },
          {
            "$ref": "#/parameters/recognitionModel"
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          },
          {
            "$ref": "#/parameters/detectionModel"
          },
          {
            "in": "body",
            "name": "ImageUrl",
            "description": "A JSON document with a URL pointing to the image that is to be analyzed.",
            "required": true,
            "x-ms-parameter-location": "method",
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/ImageUrl"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of face entries ranked by face rectangle size in descending order. An empty response indicates no faces detected.",
            "schema": {
              "$ref": "#/definitions/DetectedFaces"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Detect with url example": {
            "$ref": "./examples/DetectWithUrl.json"
          }
        }
      }
    },
    "/facelists/{faceListId}/persistedfaces": {
      "post": {
        "description": "Add a face to a specified face list, up to 1,000 faces.\n<br /> To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [FaceList - Delete Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/deleteface) or [FaceList - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better detection and recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same face list are processed sequentially and to/from different face lists are in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [FaceList - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |",
        "operationId": "FaceList_AddFaceFromUrl",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "$ref": "#/parameters/detectionModel"
          },
          {
            "in": "body",
            "name": "ImageUrl",
            "description": "A JSON document with a URL pointing to the image that is to be analyzed.",
            "required": true,
            "x-ms-parameter-location": "method",
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/ImageUrl"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns a new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create face list face example": {
            "$ref": "./examples/AddFaceListFaceFromUrl.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/persons": {
      "post": {
        "description": "Create a new person in a specified large person group.",
        "operationId": "LargePersonGroupPerson_Create",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for creating new person.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns a new personId created.",
            "schema": {
              "$ref": "#/definitions/Person"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create new person for large person group example": {
            "$ref": "./examples/CreateNewLargePersonGroupPerson.json"
          }
        }
      },
      "get": {
        "description": "List all persons in a large person group, and retrieve person information (including personId, name, userData and persistedFaceIds of registered faces of the person).",
        "operationId": "LargePersonGroupPerson_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "in": "query",
            "name": "start",
            "description": "Starting person id to return (used to list a range of persons).",
            "required": false,
            "type": "string"
          },
          {
            "in": "query",
            "name": "top",
            "description": "Number of persons to return starting with the person id indicated by the 'start' parameter.",
            "required": false,
            "type": "integer",
            "maximum": 1000,
            "minimum": 1
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of person information that belong to the large person group.",
            "schema": {
              "$ref": "#/definitions/Persons"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List persons in person group": {
            "$ref": "./examples/ListLargePersonGroupPersons.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/persons/{personId}": {
      "delete": {
        "description": "Delete an existing person from a large person group. The persistedFaceId, userData, person name and face feature in the person entry will all be deleted.",
        "operationId": "LargePersonGroupPerson_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete an existing person example": {
            "$ref": "./examples/DeleteLargePersonGroupPerson.json"
          }
        }
      },
      "get": {
        "description": "Retrieve a person's name and userData, and the persisted faceIds representing the registered person face feature.",
        "operationId": "LargePersonGroupPerson_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the person's information.",
            "schema": {
              "$ref": "#/definitions/Person"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get person example": {
            "$ref": "./examples/GetLargePersonGroupPerson.json"
          }
        }
      },
      "patch": {
        "description": "Update name or userData of a person.",
        "operationId": "LargePersonGroupPerson_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for person update operation.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update person example": {
            "$ref": "./examples/UpdateLargePersonGroupPerson.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces/{persistedFaceId}": {
      "delete": {
        "description": "Delete a face from a person in a large person group by specified largePersonGroupId, personId and persistedFaceId.\n<br /> Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.",
        "operationId": "LargePersonGroupPerson_DeleteFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete face from person example": {
            "$ref": "./examples/DeleteLargePersonGroupPersonFace.json"
          }
        }
      },
      "get": {
        "description": "Retrieve information about a persisted face (specified by persistedFaceId, personId and its belonging largePersonGroupId).",
        "operationId": "LargePersonGroupPerson_GetFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns target persisted face's information (persistedFaceId and userData).",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get persisted face example": {
            "$ref": "./examples/GetLargePersonGroupPersistedFace.json"
          }
        }
      },
      "patch": {
        "description": "Update a person persisted face's userData field.",
        "operationId": "LargePersonGroupPerson_UpdateFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating persisted face.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/UpdateFaceRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update person face example": {
            "$ref": "./examples/UpdateLargePersonGroupPersonFace.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}": {
      "put": {
        "description": "Create a new large person group with user-specified largePersonGroupId, name, an optional userData and recognitionModel.\n<br /> A large person group is the container of the uploaded person data, including face recognition feature, and up to 1,000,000\npeople.\n<br /> After creation, use [LargePersonGroup Person - Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/create) to add person into the group, and call [LargePersonGroup - Train](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/train) to get this group ready for [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify).\n<br /> No image will be stored. Only the person's extracted face features and userData will be stored on server until [LargePersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/delete) or [LargePersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/delete) is called.\n<br/>'recognitionModel' should be specified to associate with this large person group. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing large person group will use the recognition model that's already associated with the collection. Existing face features in a large person group can't be updated to features extracted by another version of recognition model.\n* 'recognition_01': The default recognition model for [LargePersonGroup - Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/create). All those large person groups created before 2019 March are bonded with this recognition model.\n* 'recognition_02': Recognition model released in 2019 March.\n* 'recognition_03': Recognition model released in 2020 May. 'recognition_03' is recommended since its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.\n\nLarge person group quota:\n* Free-tier subscription quota: 1,000 large person groups.\n* S0-tier subscription quota: 1,000,000 large person groups.",
        "operationId": "LargePersonGroup_Create",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for creating new large person group.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/MetaDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create new large person group example": {
            "$ref": "./examples/CreateNewLargePersonGroup.json"
          }
        }
      },
      "delete": {
        "description": "Delete an existing large person group. Persisted face features of all people in the large person group will also be deleted.",
        "operationId": "LargePersonGroup_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete a large person group example": {
            "$ref": "./examples/DeleteLargePersonGroup.json"
          }
        }
      },
      "get": {
        "description": "Retrieve the information of a large person group, including its name, userData and recognitionModel. This API returns large person group information only, use [LargePersonGroup Person - List](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/list) instead to retrieve person information under the large person group.\n",
        "operationId": "LargePersonGroup_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the large person group's information.",
            "schema": {
              "$ref": "#/definitions/LargePersonGroup"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get large person group example": {
            "$ref": "./examples/GetLargePersonGroup.json"
          }
        }
      },
      "patch": {
        "description": "Update an existing large person group's display name and userData. The properties which does not appear in request body will not be updated.",
        "operationId": "LargePersonGroup_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating large person group.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update large person group example": {
            "$ref": "./examples/UpdateLargePersonGroup.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/training": {
      "get": {
        "description": "Retrieve the training status of a large person group (completed or ongoing).",
        "operationId": "LargePersonGroup_GetTrainingStatus",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the large person group's training status.",
            "schema": {
              "$ref": "#/definitions/TrainingStatus"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get large person group's training status example": {
            "$ref": "./examples/GetLargePersonGroupTrainingStatus.json"
          }
        }
      }
    },
    "/largepersongroups": {
      "get": {
        "description": "List all existing large person groups’ largePersonGroupId, name, userData and recognitionModel.<br />\n* Large person groups are stored in alphabetical order of largePersonGroupId.\n* \"start\" parameter (string, optional) is a user-provided largePersonGroupId value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry’s Id of the current call.\n<br />\nFor example, total 5 large person groups: \"group1\", ..., \"group5\".\n<br /> \"start=&top=\" will return all 5 groups.\n<br /> \"start=&top=2\" will return \"group1\", \"group2\".\n<br /> \"start=group2&top=3\" will return \"group3\", \"group4\", \"group5\".\n",
        "operationId": "LargePersonGroup_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "query",
            "name": "start",
            "description": "List large person groups from the least largePersonGroupId greater than the \"start\".",
            "required": false,
            "type": "string",
            "maxLength": 64
          },
          {
            "in": "query",
            "name": "top",
            "description": "The number of large person groups to list.",
            "required": false,
            "type": "integer",
            "default": 1000,
            "maximum": 1000,
            "minimum": 1
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of large person groups and their information.",
            "schema": {
              "$ref": "#/definitions/LargePersonGroups"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List large person groups example": {
            "$ref": "./examples/ListLargePersonGroups.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/train": {
      "post": {
        "description": "Queue a large person group training task, the training task may not be started immediately.",
        "operationId": "LargePersonGroup_Train",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          }
        ],
        "responses": {
          "202": {
            "description": "The training task was queued successfully."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Queue large person group training": {
            "$ref": "./examples/QueueLargePersonGroupTraining.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces": {
      "post": {
        "description": "Add a face to a person into a large person group for face identification or verification. To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [LargePersonGroup PersonFace - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/deleteface), [LargePersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/delete) or [LargePersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [LargePersonGroup Person - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |",
        "operationId": "LargePersonGroupPerson_AddFaceFromUrl",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "$ref": "#/parameters/detectionModel"
          },
          {
            "in": "body",
            "name": "ImageUrl",
            "description": "A JSON document with a URL pointing to the image that is to be analyzed.",
            "required": true,
            "x-ms-parameter-location": "method",
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/ImageUrl"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Add Person face example": {
            "$ref": "./examples/AddLargePersonGroupPersonFaceFromUrl.json"
          }
        }
      }
    },
    "/largefacelists/{largeFaceListId}": {
      "put": {
        "description": "Create an empty large face list with user-specified largeFaceListId, name, an optional userData and recognitionModel.\n<br /> Large face list is a list of faces, up to 1,000,000 faces, and used by [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar).\n<br /> After creation, user should use [LargeFaceList Face - Add](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/addfacefromurl) to import the faces and [LargeFaceList - Train](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/train) to make it ready for [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar). No image will be stored. Only the extracted face features are stored on server until [LargeFaceList - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/delete) is called.\n<br /> Find Similar is used for scenario like finding celebrity-like faces, similar face filtering, or as a light way face identification. But if the actual use is to identify person, please use [PersonGroup](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup) / [LargePersonGroup](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup) and [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify).\n<br/>'recognitionModel' should be specified to associate with this large face list. The default value for 'recognitionModel' is 'recognition_01', if the latest model needed, please explicitly specify the model you need in this parameter. New faces that are added to an existing large face list will use the recognition model that's already associated with the collection. Existing face features in a large face list can't be updated to features extracted by another version of recognition model.\n* 'recognition_01': The default recognition model for [LargeFaceList- Create](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/create). All those large face lists created before 2019 March are bonded with this recognition model.\n* 'recognition_02': Recognition model released in 2019 March.\n* 'recognition_03': Recognition model released in 2020 May. 'recognition_03' is recommended since its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.\n\nLarge face list quota:\n* Free-tier subscription quota: 64 large face lists.\n* S0-tier subscription quota: 1,000,000 large face lists.",
        "operationId": "LargeFaceList_Create",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for creating a large face list.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/MetaDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create new large face list example": {
            "$ref": "./examples/CreateNewLargeFaceList.json"
          }
        }
      },
      "get": {
        "description": "Retrieve a large face list’s largeFaceListId, name, userData and recognitionModel.",
        "operationId": "LargeFaceList_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the large face list's information.",
            "schema": {
              "$ref": "#/definitions/LargeFaceList"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get large face list example": {
            "$ref": "./examples/GetLargeFaceList.json"
          }
        }
      },
      "patch": {
        "description": "Update information of a large face list.",
        "operationId": "LargeFaceList_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating a large face list.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/NameAndUserDataContract"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update large face list example": {
            "$ref": "./examples/UpdateLargeFaceList.json"
          }
        }
      },
      "delete": {
        "description": "Delete a specified large face list.",
        "operationId": "LargeFaceList_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete large face list example": {
            "$ref": "./examples/DeleteLargeFaceList.json"
          }
        }
      }
    },
    "/largefacelists/{largeFaceListId}/training": {
      "get": {
        "description": "Retrieve the training status of a large face list (completed or ongoing).",
        "operationId": "LargeFaceList_GetTrainingStatus",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the large face list's training status.",
            "schema": {
              "$ref": "#/definitions/TrainingStatus"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get large face list's training status example": {
            "$ref": "./examples/GetLargeFaceListTrainingStatus.json"
          }
        }
      }
    },
    "/largefacelists": {
      "get": {
        "description": "List large face lists’ information of largeFaceListId, name, userData and recognitionModel. <br /> \nTo get face information inside largeFaceList use [LargeFaceList Face - Get](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/getface)<br />\n* Large face lists are stored in alphabetical order of largeFaceListId.\n* \"start\" parameter (string, optional) is a user-provided largeFaceListId value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\n* \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry’s Id of the current call.\n<br />\nFor example, total 5 large person lists: \"list1\", ..., \"list5\".\n<br /> \"start=&top=\" will return all 5 lists.\n<br /> \"start=&top=2\" will return \"list1\", \"list2\".\n<br /> \"start=list2&top=3\" will return \"list3\", \"list4\", \"list5\".\n",
        "operationId": "LargeFaceList_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/returnRecognitionModel"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of largeFaceList.",
            "schema": {
              "$ref": "#/definitions/LargeFaceLists"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List large face lists example": {
            "$ref": "./examples/ListLargeFaceLists.json"
          }
        }
      }
    },
    "/largefacelists/{largeFaceListId}/train": {
      "post": {
        "description": "Queue a large face list training task, the training task may not be started immediately.",
        "operationId": "LargeFaceList_Train",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          }
        ],
        "responses": {
          "202": {
            "description": "The training task was queued successfully."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Queue large face list training": {
            "$ref": "./examples/QueueLargeFaceListTraining.json"
          }
        }
      }
    },
    "/largefacelists/{largeFaceListId}/persistedfaces/{persistedFaceId}": {
      "delete": {
        "description": "Delete a face from a large face list by specified largeFaceListId and persistedFaceId.\n<br /> Adding/deleting faces to/from a same large face list are processed sequentially and to/from different large face lists are in parallel.",
        "operationId": "LargeFaceList_DeleteFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete face in large face list example": {
            "$ref": "./examples/DeleteLargeFaceListFace.json"
          }
        }
      },
      "get": {
        "description": "Retrieve information about a persisted face (specified by persistedFaceId and its belonging largeFaceListId).",
        "operationId": "LargeFaceList_GetFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns target persisted face's information (persistedFaceId and userData).",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get persisted face example": {
            "$ref": "./examples/GetLargeFaceListPersistedFace.json"
          }
        }
      },
      "patch": {
        "description": "Update a persisted face's userData field.",
        "operationId": "LargeFaceList_UpdateFace",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "$ref": "#/parameters/persistedFaceId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating persisted face.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/UpdateFaceRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update face example": {
            "$ref": "./examples/UpdateLargeFaceListFace.json"
          }
        }
      }
    },
    "/largefacelists/{largeFaceListId}/persistedfaces": {
      "post": {
        "description": "Add a face to a specified large face list, up to 1,000,000 faces.\n<br /> To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [LargeFaceList Face - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/deleteface) or [LargeFaceList - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same face list are processed sequentially and to/from different face lists are in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [LargeFaceList - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |\n\nQuota:\n* Free-tier subscription quota: 1,000 faces per large face list.\n* S0-tier subscription quota: 1,000,000 faces per large face list.",
        "operationId": "LargeFaceList_AddFaceFromUrl",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "$ref": "#/parameters/detectionModel"
          },
          {
            "in": "body",
            "name": "ImageUrl",
            "description": "A JSON document with a URL pointing to the image that is to be analyzed.",
            "required": true,
            "x-ms-parameter-location": "method",
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/ImageUrl"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns a new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Create large face list face example": {
            "$ref": "./examples/AddLargeFaceListFaceFromUrl.json"
          }
        }
      },
      "get": {
        "description": "List all faces in a large face list, and retrieve face information (including userData and persistedFaceIds of registered faces of the face).",
        "operationId": "LargeFaceList_ListFaces",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "in": "query",
            "name": "start",
            "description": "Starting face id to return (used to list a range of faces).",
            "required": false,
            "type": "string"
          },
          {
            "in": "query",
            "name": "top",
            "description": "Number of faces to return starting with the face id indicated by the 'start' parameter.",
            "required": false,
            "type": "integer",
            "maximum": 1000,
            "minimum": 1
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of face information that belong to the large face list.",
            "schema": {
              "$ref": "#/definitions/PersistedFaces"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List faces in large face list": {
            "$ref": "./examples/ListLargeFaceListFaces.json"
          }
        }
      }
    },
    "/snapshots": {
      "post": {
        "description": "Submit an operation to take a snapshot of face list, large face list, person group or large person group, with user-specified snapshot type, source object id, apply scope and an optional user data.<br />\nThe snapshot interfaces are for users to backup and restore their face data from one face subscription to another, inside same region or across regions. The workflow contains two phases, user first calls Snapshot - Take to create a copy of the source object and store it as a snapshot, then calls Snapshot - Apply to paste the snapshot to target subscription. The snapshots are stored in a centralized location (per Azure instance), so that they can be applied cross accounts and regions.<br />\nTaking snapshot is an asynchronous operation. An operation id can be obtained from the \"Operation-Location\" field in response header, to be used in OperationStatus - Get for tracking the progress of creating the snapshot. The snapshot id will be included in the \"resourceLocation\" field in OperationStatus - Get response when the operation status is \"succeeded\".<br />\nSnapshot taking time depends on the number of person and face entries in the source object. It could be in seconds, or up to several hours for 1,000,000 persons with multiple faces.<br />\nSnapshots will be automatically expired and cleaned in 48 hours after it is created by Snapshot - Take. User can delete the snapshot using Snapshot - Delete by themselves any time before expiration.<br />\nTaking snapshot for a certain object will not block any other operations against the object. All read-only operations (Get/List and Identify/FindSimilar/Verify) can be conducted as usual. For all writable operations, including Add/Update/Delete the source object or its persons/faces and Train, they are not blocked but not recommended because writable updates may not be reflected on the snapshot during its taking. After snapshot taking is completed, all readable and writable operations can work as normal. Snapshot will also include the training results of the source object, which means target subscription the snapshot applied to does not need re-train the target object before calling Identify/FindSimilar.<br />\n* Free-tier subscription quota: 100 take operations per month.\n* S0-tier subscription quota: 100 take operations per day.",
        "operationId": "Snapshot_Take",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "body",
            "name": "body",
            "description": "Request body for taking a snapshot.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/TakeSnapshotRequest"
            }
          }
        ],
        "responses": {
          "202": {
            "description": "The snapshot taking task was queued successfully.",
            "headers": {
              "Operation-Location": {
                "description": "Operation location with an operation id used to track the progress of taking snapshot. The returned id is the operation id, rather than snapshot id. Snapshot id can be obtained only when the operation status becomes \"succeeded\" in OperationStatus - Get.",
                "type": "string"
              }
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Take a snapshot example": {
            "$ref": "./examples/TakeSnapshot.json"
          }
        }
      },
      "get": {
        "description": "List all accessible snapshots with related information, including snapshots that were taken by the user, or snapshots to be applied to the user (subscription id was included in the applyScope in Snapshot - Take).",
        "operationId": "Snapshot_List",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "in": "query",
            "name": "type",
            "description": "User specified object type as a search filter.",
            "required": false,
            "type": "string",
            "enum": [
              "FaceList",
              "LargeFaceList",
              "LargePersonGroup",
              "PersonGroup"
            ],
            "x-ms-enum": {
              "name": "SnapshotObjectType",
              "modelAsString": false
            }
          },
          {
            "$ref": "#/parameters/applyScope"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of snapshots with snapshot information.",
            "schema": {
              "$ref": "#/definitions/Snapshots"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "List snapshots example": {
            "$ref": "./examples/ListSnapshots.json"
          }
        }
      }
    },
    "/snapshots/{snapshotId}": {
      "get": {
        "description": "Retrieve information about a snapshot. Snapshot is only accessible to the source subscription who took it, and target subscriptions included in the applyScope in Snapshot - Take.",
        "operationId": "Snapshot_Get",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/snapshotId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the snapshot's information.",
            "schema": {
              "$ref": "#/definitions/Snapshot"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get snapshot example": {
            "$ref": "./examples/GetSnapshot.json"
          }
        }
      },
      "patch": {
        "description": "Update the information of a snapshot. Only the source subscription who took the snapshot can update the snapshot.",
        "operationId": "Snapshot_Update",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/snapshotId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for updating a snapshot.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/UpdateSnapshotRequest"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Update snapshot example": {
            "$ref": "./examples/UpdateSnapshot.json"
          }
        }
      },
      "delete": {
        "description": "Delete an existing snapshot according to the snapshotId. All object data and information in the snapshot will also be deleted. Only the source subscription who took the snapshot can delete the snapshot. If the user does not delete a snapshot with this API, the snapshot will still be automatically deleted in 48 hours after creation.",
        "operationId": "Snapshot_Delete",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/snapshotId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an empty response body."
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Delete snapshot example": {
            "$ref": "./examples/DeleteSnapshot.json"
          }
        }
      }
    },
    "/snapshots/{snapshotId}/apply": {
      "post": {
        "description": "Submit an operation to apply a snapshot to current subscription. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it.<br />\nThe snapshot interfaces are for users to backup and restore their face data from one face subscription to another, inside same region or across regions. The workflow contains two phases, user first calls Snapshot - Take to create a copy of the source object and store it as a snapshot, then calls Snapshot - Apply to paste the snapshot to target subscription. The snapshots are stored in a centralized location (per Azure instance), so that they can be applied cross accounts and regions.<br />\nApplying snapshot is an asynchronous operation. An operation id can be obtained from the \"Operation-Location\" field in response header, to be used in OperationStatus - Get for tracking the progress of applying the snapshot. The target object id will be included in the \"resourceLocation\" field in OperationStatus - Get response when the operation status is \"succeeded\".<br />\nSnapshot applying time depends on the number of person and face entries in the snapshot object. It could be in seconds, or up to 1 hour for 1,000,000 persons with multiple faces.<br />\nSnapshots will be automatically expired and cleaned in 48 hours after it is created by Snapshot - Take. So the target subscription is required to apply the snapshot in 48 hours since its creation.<br />\nApplying a snapshot will not block any other operations against the target object, however it is not recommended because the correctness cannot be guaranteed during snapshot applying. After snapshot applying is completed, all operations towards the target object can work as normal. Snapshot also includes the training results of the source object, which means target subscription the snapshot applied to does not need re-train the target object before calling Identify/FindSimilar.<br />\nOne snapshot can be applied multiple times in parallel, while currently only CreateNew apply mode is supported, which means the apply operation will fail if target subscription already contains an object of same type and using the same objectId. Users can specify the \"objectId\" in request body to avoid such conflicts.<br />\n* Free-tier subscription quota: 100 apply operations per month.\n* S0-tier subscription quota: 100 apply operations per day.",
        "operationId": "Snapshot_Apply",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/snapshotId"
          },
          {
            "in": "body",
            "name": "body",
            "description": "Request body for applying a snapshot.",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/ApplySnapshotRequest"
            }
          }
        ],
        "responses": {
          "202": {
            "description": "The snapshot applying task was queued successfully.",
            "headers": {
              "Operation-Location": {
                "description": "Operation location with an operation id used to track the progress of applying the snapshot by OperationStatus - Get.",
                "type": "string"
              }
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Apply snapshot example": {
            "$ref": "./examples/ApplySnapshot.json"
          }
        }
      }
    },
    "/operations/{operationId}": {
      "get": {
        "description": "Retrieve the status of a take/apply snapshot operation.",
        "operationId": "Snapshot_GetOperationStatus",
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "parameters": [
          {
            "$ref": "#/parameters/operationId"
          }
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the snapshot operation's status.",
            "schema": {
              "$ref": "#/definitions/OperationStatus"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Get snapshot operation status example": {
            "$ref": "./examples/GetSnapshotOperationStatus.json"
          }
        }
      }
    }
  },
  "definitions": {
    "APIError": {
      "description": "Error information returned by the API",
      "type": "object",
      "properties": {
        "error": {
          "$ref": "#/definitions/Error"
        }
      }
    },
    "Error": {
      "description": "Error body.",
      "type": "object",
      "properties": {
        "code": {
          "type": "string"
        },
        "message": {
          "type": "string"
        }
      }
    },
    "DetectedFaces": {
      "type": "array",
      "items": {
        "$ref": "#/definitions/DetectedFace"
      }
    },
    "DetectedFace": {
      "description": "Detected Face object.",
      "required": [
        "faceRectangle"
      ],
      "type": "object",
      "properties": {
        "faceId": {
          "format": "uuid",
          "type": "string"
        },
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel"
        },
        "faceRectangle": {
          "$ref": "#/definitions/FaceRectangle"
        },
        "faceLandmarks": {
          "$ref": "#/definitions/FaceLandmarks"
        },
        "faceAttributes": {
          "$ref": "#/definitions/FaceAttributes"
        }
      }
    },
    "FaceRectangle": {
      "description": "A rectangle within which a face can be found",
      "required": [
        "width",
        "height",
        "left",
        "top"
      ],
      "type": "object",
      "properties": {
        "width": {
          "format": "int32",
          "description": "The width of the rectangle, in pixels.",
          "type": "integer"
        },
        "height": {
          "format": "int32",
          "description": "The height of the rectangle, in pixels.",
          "type": "integer"
        },
        "left": {
          "format": "int32",
          "description": "The distance from the left edge if the image to the left edge of the rectangle, in pixels.",
          "type": "integer"
        },
        "top": {
          "format": "int32",
          "description": "The distance from the top edge if the image to the top edge of the rectangle, in pixels.",
          "type": "integer"
        }
      }
    },
    "Coordinate": {
      "description": "Coordinates within an image",
      "required": [
        "x",
        "y"
      ],
      "type": "object",
      "properties": {
        "x": {
          "description": "The horizontal component, in pixels.",
          "type": "number"
        },
        "y": {
          "description": "The vertical component, in pixels.",
          "type": "number"
        }
      }
    },
    "FaceLandmarks": {
      "description": "A collection of 27-point face landmarks pointing to the important positions of face components.",
      "type": "object",
      "properties": {
        "pupilLeft": {
          "$ref": "#/definitions/Coordinate"
        },
        "pupilRight": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseTip": {
          "$ref": "#/definitions/Coordinate"
        },
        "mouthLeft": {
          "$ref": "#/definitions/Coordinate"
        },
        "mouthRight": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyebrowLeftOuter": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyebrowLeftInner": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeLeftOuter": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeLeftTop": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeLeftBottom": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeLeftInner": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyebrowRightInner": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyebrowRightOuter": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeRightInner": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeRightTop": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeRightBottom": {
          "$ref": "#/definitions/Coordinate"
        },
        "eyeRightOuter": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseRootLeft": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseRootRight": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseLeftAlarTop": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseRightAlarTop": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseLeftAlarOutTip": {
          "$ref": "#/definitions/Coordinate"
        },
        "noseRightAlarOutTip": {
          "$ref": "#/definitions/Coordinate"
        },
        "upperLipTop": {
          "$ref": "#/definitions/Coordinate"
        },
        "upperLipBottom": {
          "$ref": "#/definitions/Coordinate"
        },
        "underLipTop": {
          "$ref": "#/definitions/Coordinate"
        },
        "underLipBottom": {
          "$ref": "#/definitions/Coordinate"
        }
      }
    },
    "FaceAttributes": {
      "description": "Face Attributes",
      "type": "object",
      "properties": {
        "age": {
          "description": "Age in years",
          "type": "number"
        },
        "gender": {
          "description": "Possible gender of the face.",
          "enum": [
            "male",
            "female"
          ],
          "type": "string",
          "x-ms-enum": {
            "name": "Gender",
            "modelAsString": false
          }
        },
        "smile": {
          "description": "Smile intensity, a number between [0,1] ",
          "$ref": "#/definitions/Level"
        },
        "facialHair": {
          "description": "Properties describing facial hair attributes.",
          "$ref": "#/definitions/FacialHair"
        },
        "glasses": {
          "description": "Glasses type if any of the face.",
          "enum": [
            "noGlasses",
            "readingGlasses",
            "sunglasses",
            "swimmingGoggles"
          ],
          "type": "string",
          "x-ms-enum": {
            "name": "GlassesType",
            "modelAsString": false
          }
        },
        "headPose": {
          "description": "Properties indicating head pose of the face.",
          "$ref": "#/definitions/HeadPose"
        },
        "emotion": {
          "description": "Properties describing facial emotion in form of confidence ranging from 0 to 1.",
          "$ref": "#/definitions/Emotion"
        },
        "hair": {
          "description": "Properties describing hair attributes.",
          "$ref": "#/definitions/Hair"
        },
        "makeup": {
          "description": "Properties describing present makeups on a given face.",
          "$ref": "#/definitions/Makeup"
        },
        "occlusion": {
          "description": "Properties describing occlusions on a given face.",
          "$ref": "#/definitions/Occlusion"
        },
        "accessories": {
          "description": "Properties describing any accessories on a given face.",
          "$ref": "#/definitions/Accessories"
        },
        "blur": {
          "description": "Properties describing any presence of blur within the image.",
          "$ref": "#/definitions/Blur"
        },
        "exposure": {
          "description": "Properties describing exposure level of the image.",
          "$ref": "#/definitions/Exposure"
        },
        "noise": {
          "description": "Properties describing noise level of the image.",
          "$ref": "#/definitions/Noise"
        }
      }
    },
    "FacialHair": {
      "description": "Properties describing facial hair attributes.",
      "type": "object",
      "properties": {
        "moustache": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "beard": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "sideburns": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "HeadPose": {
      "description": "Properties indicating head pose of the face.",
      "type": "object",
      "properties": {
        "roll": {
          "type": "number",
          "x-nullable": false
        },
        "yaw": {
          "type": "number",
          "x-nullable": false
        },
        "pitch": {
          "type": "number",
          "x-nullable": false
        }
      }
    },
    "Emotion": {
      "description": "Properties describing facial emotion in form of confidence ranging from 0 to 1.",
      "type": "object",
      "properties": {
        "anger": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "contempt": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "disgust": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "fear": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "happiness": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "neutral": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "sadness": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "surprise": {
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "Hair": {
      "description": "Properties describing hair attributes.",
      "type": "object",
      "properties": {
        "bald": {
          "description": "A number describing confidence level of whether the person is bald.",
          "x-nullable": false,
          "$ref": "#/definitions/Confidence"
        },
        "invisible": {
          "description": "A boolean value describing whether the hair is visible in the image.",
          "type": "boolean",
          "x-nullable": false
        },
        "hairColor": {
          "description": "An array of candidate colors and confidence level in the presence of each.",
          "$ref": "#/definitions/HairColors"
        }
      }
    },
    "HairColors": {
      "type": "array",
      "items": {
        "$ref": "#/definitions/HairColor"
      }
    },
    "HairColor": {
      "description": "Hair color and associated confidence",
      "type": "object",
      "properties": {
        "color": {
          "description": "Name of the hair color.",
          "enum": [
            "unknown",
            "white",
            "gray",
            "blond",
            "brown",
            "red",
            "black",
            "other"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "HairColorType",
            "modelAsString": false
          }
        },
        "confidence": {
          "x-nullable": false,
          "description": "Confidence level of the color",
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "Makeup": {
      "description": "Properties describing present makeups on a given face.",
      "type": "object",
      "properties": {
        "eyeMakeup": {
          "description": "A boolean value describing whether eye makeup is present on a face.",
          "type": "boolean",
          "x-nullable": false
        },
        "lipMakeup": {
          "description": "A boolean value describing whether lip makeup is present on a face.",
          "type": "boolean",
          "x-nullable": false
        }
      }
    },
    "Occlusion": {
      "description": "Properties describing occlusions on a given face.",
      "type": "object",
      "properties": {
        "foreheadOccluded": {
          "description": "A boolean value indicating whether forehead is occluded.",
          "type": "boolean",
          "x-nullable": false
        },
        "eyeOccluded": {
          "description": "A boolean value indicating whether eyes are occluded.",
          "type": "boolean",
          "x-nullable": false
        },
        "mouthOccluded": {
          "description": "A boolean value indicating whether the mouth is occluded.",
          "type": "boolean",
          "x-nullable": false
        }
      }
    },
    "Accessories": {
      "description": "Properties describing any accessories on a given face.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/Accessory"
      }
    },
    "Accessory": {
      "description": "Accessory item and corresponding confidence level.",
      "type": "object",
      "properties": {
        "type": {
          "description": "Type of an accessory",
          "enum": [
            "headWear",
            "glasses",
            "mask"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "AccessoryType",
            "modelAsString": false
          }
        },
        "confidence": {
          "x-nullable": false,
          "description": "Confidence level of an accessory",
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "Blur": {
      "description": "Properties describing any presence of blur within the image.",
      "type": "object",
      "properties": {
        "blurLevel": {
          "description": "An enum value indicating level of blurriness.",
          "enum": [
            "Low",
            "Medium",
            "High"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "BlurLevel",
            "modelAsString": false
          }
        },
        "value": {
          "description": "A number indicating level of blurriness ranging from 0 to 1.",
          "x-nullable": false,
          "$ref": "#/definitions/Level"
        }
      }
    },
    "Exposure": {
      "description": "Properties describing exposure level of the image.",
      "type": "object",
      "properties": {
        "exposureLevel": {
          "description": "An enum value indicating level of exposure.",
          "enum": [
            "UnderExposure",
            "GoodExposure",
            "OverExposure"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "ExposureLevel",
            "modelAsString": false
          }
        },
        "value": {
          "description": "A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure.",
          "x-nullable": false,
          "$ref": "#/definitions/Level"
        }
      }
    },
    "Noise": {
      "description": "Properties describing noise level of the image.",
      "type": "object",
      "properties": {
        "noiseLevel": {
          "description": "An enum value indicating level of noise.",
          "enum": [
            "Low",
            "Medium",
            "High"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "NoiseLevel",
            "modelAsString": false
          }
        },
        "value": {
          "description": "A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level.",
          "x-nullable": false,
          "$ref": "#/definitions/Level"
        }
      }
    },
    "FindSimilarRequest": {
      "description": "Request body for find similar operation.",
      "required": [
        "faceId"
      ],
      "type": "object",
      "properties": {
        "faceId": {
          "format": "uuid",
          "description": "FaceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call",
          "type": "string"
        },
        "faceListId": {
          "description": "An existing user-specified unique candidate face list, created in Face List - Create a Face List. Face list contains a set of persistedFaceIds which are persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "largeFaceListId": {
          "description": "An existing user-specified unique candidate large face list, created in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "faceIds": {
          "description": "An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time.",
          "maxItems": 1000,
          "type": "array",
          "items": {
            "format": "uuid",
            "type": "string"
          }
        },
        "maxNumOfCandidatesReturned": {
          "description": "The number of top similar faces returned. The valid range is [1, 1000].",
          "default": 20,
          "maximum": 1000,
          "minimum": 1,
          "type": "integer"
        },
        "mode": {
          "description": "Similar face searching mode. It can be \"matchPerson\" or \"matchFace\".",
          "default": "matchPerson",
          "enum": [
            "matchPerson",
            "matchFace"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "FindSimilarMatchMode",
            "modelAsString": false
          }
        }
      }
    },
    "SimilarFaces": {
      "type": "array",
      "items": {
        "$ref": "#/definitions/SimilarFace"
      }
    },
    "SimilarFace": {
      "description": "Response body for find similar face operation.",
      "required": [
        "confidence"
      ],
      "type": "object",
      "properties": {
        "faceId": {
          "format": "uuid",
          "description": "FaceId of candidate face when find by faceIds. faceId is created by Face - Detect and will expire 24 hours after the detection call",
          "type": "string"
        },
        "persistedFaceId": {
          "format": "uuid",
          "description": "PersistedFaceId of candidate face when find by faceListId. persistedFaceId in face list is persisted and will not expire. As showed in below response",
          "type": "string"
        },
        "confidence": {
          "description": "Similarity confidence of the candidate face. The higher confidence, the more similar. Range between [0,1].",
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "GroupRequest": {
      "description": "Request body for group request.",
      "required": [
        "faceIds"
      ],
      "type": "object",
      "properties": {
        "faceIds": {
          "description": "Array of candidate faceId created by Face - Detect. The maximum is 1000 faces",
          "maxItems": 1000,
          "type": "array",
          "items": {
            "format": "uuid",
            "type": "string",
            "x-nullable": false
          }
        }
      }
    },
    "GroupResult": {
      "description": "An array of face groups based on face similarity.",
      "required": [
        "groups"
      ],
      "type": "object",
      "properties": {
        "groups": {
          "description": "A partition of the original faces based on face similarity. Groups are ranked by number of faces",
          "type": "array",
          "items": {
            "type": "array",
            "items": {
              "format": "uuid",
              "type": "string",
              "x-nullable": false
            }
          }
        },
        "messyGroup": {
          "description": "Face ids array of faces that cannot find any similar faces from original faces.",
          "type": "array",
          "items": {
            "format": "uuid",
            "type": "string",
            "x-nullable": false
          }
        }
      }
    },
    "IdentifyRequest": {
      "description": "Request body for identify face operation.",
      "required": [
        "faceIds"
      ],
      "type": "object",
      "properties": {
        "faceIds": {
          "description": "Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10].",
          "maxItems": 10,
          "type": "array",
          "items": {
            "format": "uuid",
            "type": "string",
            "x-nullable": false
          }
        },
        "personGroupId": {
          "description": "PersonGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "largePersonGroupId": {
          "description": "LargePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "maxNumOfCandidatesReturned": {
          "description": "The range of maxNumOfCandidatesReturned is between 1 and 5 (default is 1).",
          "default": 1,
          "maximum": 5,
          "minimum": 1,
          "type": "integer"
        },
        "confidenceThreshold": {
          "description": "Confidence threshold of identification, used to judge whether one face belong to one person. The range of confidenceThreshold is [0, 1] (default specified by algorithm).",
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "IdentifyResults": {
      "type": "array",
      "items": {
        "$ref": "#/definitions/IdentifyResult"
      }
    },
    "IdentifyResult": {
      "description": "Response body for identify face operation.",
      "required": [
        "faceId",
        "candidates"
      ],
      "type": "object",
      "properties": {
        "faceId": {
          "format": "uuid",
          "description": "FaceId of the query face",
          "type": "string"
        },
        "candidates": {
          "description": "Identified person candidates for that face (ranked by confidence). Array size should be no larger than input maxNumOfCandidatesReturned. If no person is identified, will return an empty array.",
          "type": "array",
          "items": {
            "$ref": "#/definitions/IdentifyCandidate"
          }
        }
      }
    },
    "IdentifyCandidate": {
      "description": "All possible faces that may qualify.",
      "required": [
        "personId",
        "confidence"
      ],
      "type": "object",
      "properties": {
        "personId": {
          "format": "uuid",
          "description": "Id of candidate",
          "type": "string"
        },
        "confidence": {
          "description": "Confidence threshold of identification, used to judge whether one face belong to one person. The range of confidenceThreshold is [0, 1] (default specified by algorithm).",
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "VerifyFaceToPersonRequest": {
      "description": "Request body for face to person verification.",
      "required": [
        "faceId",
        "personId"
      ],
      "type": "object",
      "properties": {
        "faceId": {
          "format": "uuid",
          "description": "FaceId of the face, comes from Face - Detect",
          "type": "string"
        },
        "personGroupId": {
          "description": "Using existing personGroupId and personId for fast loading a specified person. personGroupId is created in PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "largePersonGroupId": {
          "description": "Using existing largePersonGroupId and personId for fast loading a specified person. largePersonGroupId is created in LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "personId": {
          "format": "uuid",
          "description": "Specify a certain person in a person group or a large person group. personId is created in PersonGroup Person - Create or LargePersonGroup Person - Create.",
          "type": "string"
        }
      }
    },
    "VerifyFaceToFaceRequest": {
      "description": "Request body for face to face verification.",
      "required": [
        "faceId1",
        "faceId2"
      ],
      "type": "object",
      "properties": {
        "faceId1": {
          "format": "uuid",
          "description": "FaceId of the first face, comes from Face - Detect",
          "type": "string"
        },
        "faceId2": {
          "format": "uuid",
          "description": "FaceId of the second face, comes from Face - Detect",
          "type": "string"
        }
      }
    },
    "VerifyResult": {
      "description": "Result of the verify operation.",
      "required": [
        "isIdentical",
        "confidence"
      ],
      "type": "object",
      "properties": {
        "isIdentical": {
          "description": "True if the two faces belong to the same person or the face belongs to the person, otherwise false.",
          "type": "boolean"
        },
        "confidence": {
          "description": "A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override \"isIdentical\" and fine-tune the result on their own data.",
          "$ref": "#/definitions/Confidence"
        }
      }
    },
    "FaceList": {
      "description": "Face list object.",
      "required": [
        "faceListId"
      ],
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/MetaDataContract"
        }
      ],
      "properties": {
        "faceListId": {
          "description": "FaceListId of the target face list.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "persistedFaces": {
          "description": "Persisted faces within the face list.",
          "$ref": "#/definitions/PersistedFaces"
        }
      }
    },
    "FaceLists": {
      "description": "An array of face list results, with fields of faceListId, name and userData",
      "type": "array",
      "items": {
        "$ref": "#/definitions/FaceList"
      }
    },
    "PersonGroup": {
      "description": "Person group object.",
      "required": [
        "personGroupId"
      ],
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/MetaDataContract"
        }
      ],
      "properties": {
        "personGroupId": {
          "description": "PersonGroupId of the target person group.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        }
      }
    },
    "PersonGroups": {
      "description": "An array of person groups.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/PersonGroup"
      }
    },
    "Person": {
      "description": "Person object.",
      "required": [
        "personId"
      ],
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/NameAndUserDataContract"
        }
      ],
      "properties": {
        "personId": {
          "format": "uuid",
          "description": "PersonId of the target face list.",
          "type": "string"
        },
        "persistedFaceIds": {
          "description": "PersistedFaceIds of registered faces in the person. These persistedFaceIds are returned from Person - Add a Person Face, and will not expire.",
          "type": "array",
          "items": {
            "format": "uuid",
            "type": "string",
            "x-nullable": false
          }
        }
      }
    },
    "Persons": {
      "description": "An array of Persons.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/Person"
      }
    },
    "PersistedFace": {
      "description": "PersonFace object.",
      "required": [
        "persistedFaceId"
      ],
      "type": "object",
      "properties": {
        "persistedFaceId": {
          "format": "uuid",
          "description": "The persistedFaceId of the target face, which is persisted and will not expire. Different from faceId created by Face - Detect and will expire in 24 hours after the detection call.",
          "type": "string"
        },
        "userData": {
          "description": "User-provided data attached to the face. The size limit is 1KB.",
          "maxLength": 1024,
          "type": "string"
        }
      }
    },
    "PersistedFaces": {
      "description": "An array of persisted faces within the face list or large face list.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/PersistedFace"
      }
    },
    "LargeFaceList": {
      "description": "Large face list object.",
      "required": [
        "largeFaceListId"
      ],
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/MetaDataContract"
        }
      ],
      "properties": {
        "largeFaceListId": {
          "description": "LargeFaceListId of the target large face list.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        }
      }
    },
    "LargeFaceLists": {
      "description": "An array of large face list results, with fields of largeFaceListId, name and userData",
      "type": "array",
      "items": {
        "$ref": "#/definitions/LargeFaceList"
      }
    },
    "LargePersonGroup": {
      "description": "Large person group object.",
      "required": [
        "largePersonGroupId"
      ],
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/MetaDataContract"
        }
      ],
      "properties": {
        "largePersonGroupId": {
          "description": "LargePersonGroupId of the target large person groups",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        }
      }
    },
    "LargePersonGroups": {
      "description": "An array of large person groups.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/LargePersonGroup"
      }
    },
    "UpdateFaceRequest": {
      "description": "Request to update face data.",
      "type": "object",
      "properties": {
        "userData": {
          "description": "User-provided data attached to the face. The size limit is 1KB.",
          "maxLength": 1024,
          "type": "string"
        }
      }
    },
    "TrainingStatus": {
      "description": "Training status object.",
      "required": [
        "status",
        "createdDateTime"
      ],
      "type": "object",
      "properties": {
        "status": {
          "description": "Training status: notstarted, running, succeeded, failed. If the training process is waiting to perform, the status is notstarted. If the training is ongoing, the status is running. Status succeed means this person group or large person group is ready for Face - Identify, or this large face list is ready for Face - Find Similar. Status failed is often caused by no person or no persisted face exist in the person group or large person group, or no persisted face exist in the large face list.",
          "enum": [
            "nonstarted",
            "running",
            "succeeded",
            "failed"
          ],
          "type": "string",
          "x-ms-enum": {
            "name": "TrainingStatusType",
            "modelAsString": false
          }
        },
        "createdDateTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the created time of the person group, large person group or large face list.",
          "type": "string",
          "x-ms-client-name": "created"
        },
        "lastActionDateTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the last modify time of the person group, large person group or large face list, could be null value when the group is not successfully trained.",
          "type": "string",
          "x-ms-client-name": "lastAction"
        },
        "lastSuccessfulTrainingDateTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the last successful training time of the person group, large person group or large face list.",
          "type": "string",
          "x-ms-client-name": "lastSuccessfulTraining"
        },
        "message": {
          "description": "Show failure message when training failed (omitted when training succeed).",
          "type": "string"
        }
      }
    },
    "Confidence": {
      "description": "A number ranging from 0 to 1 indicating a level of confidence associated with a property.",
      "maximum": 1,
      "minimum": 0,
      "type": "number"
    },
    "Level": {
      "description": "A number ranging from 0 to 1 indicating the intensity level associated with a property.",
      "maximum": 1,
      "minimum": 0,
      "type": "number"
    },
    "NameAndUserDataContract": {
      "description": "A combination of user defined name and user specified data for the person, largePersonGroup/personGroup, and largeFaceList/faceList.",
      "type": "object",
      "properties": {
        "name": {
          "description": "User defined name, maximum length is 128.",
          "maxLength": 128,
          "type": "string"
        },
        "userData": {
          "description": "User specified data. Length should not exceed 16KB.",
          "maxLength": 16384,
          "type": "string"
        }
      }
    },
    "MetaDataContract": {
      "description": "A combination of user defined name and user specified data and recognition model name for largePersonGroup/personGroup, and largeFaceList/faceList.",
      "type": "object",
      "allOf": [
        {
          "$ref": "#/definitions/NameAndUserDataContract"
        }
      ],
      "properties": {
        "recognitionModel": {
          "$ref": "#/definitions/RecognitionModel"
        }
      }
    },
    "RecognitionModel": {
      "description": "Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need.",
      "default": "recognition_01",
      "enum": [
        "recognition_01",
        "recognition_02",
        "recognition_03"
      ],
      "type": "string",
      "x-nullable": false,
      "x-ms-enum": {
        "name": "RecognitionModel",
        "modelAsString": true
      }
    },
    "ApplyScope": {
      "description": "Array of the target Face subscription ids for the snapshot, specified by the user who created the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it.",
      "type": "array",
      "items": {
        "format": "uuid",
        "type": "string",
        "x-nullable": false
      }
    },
    "ApplySnapshotRequest": {
      "description": "Request body for applying snapshot operation.",
      "required": [
        "objectId"
      ],
      "type": "object",
      "properties": {
        "objectId": {
          "description": "User specified target object id to be created from the snapshot.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "mode": {
          "description": "Snapshot applying mode. Currently only CreateNew is supported, which means the apply operation will fail if target subscription already contains an object of same type and using the same objectId. Users can specify the \"objectId\" in request body to avoid such conflicts.",
          "default": "CreateNew",
          "enum": [
            "CreateNew"
          ],
          "type": "string",
          "x-nullable": false,
          "x-ms-enum": {
            "name": "SnapshotApplyMode",
            "modelAsString": false
          }
        }
      }
    },
    "Snapshots": {
      "description": "An array of snapshots.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/Snapshot"
      }
    },
    "Snapshot": {
      "description": "Snapshot object.",
      "required": [
        "id",
        "account",
        "type",
        "applyScope",
        "createdTime",
        "lastUpdateTime"
      ],
      "type": "object",
      "properties": {
        "id": {
          "format": "uuid",
          "description": "Snapshot id.",
          "type": "string"
        },
        "account": {
          "description": "Azure Cognitive Service Face account id of the subscriber who created the snapshot by Snapshot - Take.",
          "type": "string"
        },
        "type": {
          "description": "Type of the source object in the snapshot, specified by the subscriber who created the snapshot when calling Snapshot - Take. Currently FaceList, PersonGroup, LargeFaceList and LargePersonGroup are supported.",
          "enum": [
            "FaceList",
            "LargeFaceList",
            "LargePersonGroup",
            "PersonGroup"
          ],
          "type": "string",
          "x-ms-enum": {
            "name": "SnapshotObjectType",
            "modelAsString": false
          }
        },
        "applyScope": {
          "description": "Array of the target Face subscription ids for the snapshot, specified by the user who created the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it.",
          "$ref": "#/definitions/ApplyScope"
        },
        "userData": {
          "description": "User specified data about the snapshot for any purpose. Length should not exceed 16KB.",
          "maxLength": 16384,
          "type": "string"
        },
        "createdTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the created time of the snapshot. E.g. 2018-12-25T11:41:02.2331413Z.",
          "type": "string"
        },
        "lastUpdateTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the last time when the snapshot was created or updated by Snapshot - Update. E.g. 2018-12-25T11:51:27.8705696Z.",
          "type": "string"
        }
      }
    },
    "TakeSnapshotRequest": {
      "description": "Request body for taking snapshot operation.",
      "required": [
        "type",
        "objectId",
        "applyScope"
      ],
      "type": "object",
      "properties": {
        "type": {
          "description": "User specified type for the source object to take snapshot from. Currently FaceList, PersonGroup, LargeFaceList and LargePersonGroup are supported.",
          "enum": [
            "FaceList",
            "LargeFaceList",
            "LargePersonGroup",
            "PersonGroup"
          ],
          "type": "string",
          "x-ms-enum": {
            "name": "SnapshotObjectType",
            "modelAsString": false
          }
        },
        "objectId": {
          "description": "User specified source object id to take snapshot from.",
          "maxLength": 64,
          "pattern": "^[a-z0-9-_]+$",
          "type": "string"
        },
        "applyScope": {
          "description": "User specified array of target Face subscription ids for the snapshot. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it.",
          "$ref": "#/definitions/ApplyScope"
        },
        "userData": {
          "description": "User specified data about the snapshot for any purpose. Length should not exceed 16KB.",
          "maxLength": 16384,
          "type": "string"
        }
      }
    },
    "UpdateSnapshotRequest": {
      "description": "Request body for updating a snapshot, with a combination of user defined apply scope and user specified data.",
      "type": "object",
      "properties": {
        "applyScope": {
          "description": "Array of the target Face subscription ids for the snapshot, specified by the user who created the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it.",
          "$ref": "#/definitions/ApplyScope"
        },
        "userData": {
          "description": "User specified data about the snapshot for any purpose. Length should not exceed 16KB.",
          "maxLength": 16384,
          "type": "string"
        }
      }
    },
    "OperationStatus": {
      "description": "Operation status object. Operation refers to the asynchronous backend task including taking a snapshot and applying a snapshot.",
      "required": [
        "status",
        "createdTime"
      ],
      "type": "object",
      "properties": {
        "status": {
          "description": "Operation status: notstarted, running, succeeded, failed. If the operation is requested and waiting to perform, the status is notstarted. If the operation is ongoing in backend, the status is running. Status succeeded means the operation is completed successfully, specifically for snapshot taking operation, it illustrates the snapshot is well taken and ready to apply, and for snapshot applying operation, it presents the target object has finished creating by the snapshot and ready to be used. Status failed is often caused by editing the source object while taking the snapshot or editing the target object while applying the snapshot before completion, see the field \"message\" to check the failure reason.",
          "enum": [
            "notstarted",
            "running",
            "succeeded",
            "failed"
          ],
          "type": "string",
          "x-ms-enum": {
            "name": "OperationStatusType",
            "modelAsString": false
          }
        },
        "createdTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the time when the operation (take or apply a snapshot) is requested. E.g. 2018-12-25T11:41:02.2331413Z.",
          "type": "string"
        },
        "lastActionTime": {
          "format": "date-time",
          "description": "A combined UTC date and time string that describes the last time the operation (take or apply a snapshot) is actively migrating data. The lastActionTime will keep increasing until the operation finishes. E.g. 2018-12-25T11:51:27.8705696Z.",
          "type": "string"
        },
        "resourceLocation": {
          "description": "When the operation succeeds successfully, for snapshot taking operation the snapshot id will be included in this field, and for snapshot applying operation, the path to get the target object will be returned in this field.",
          "type": "string"
        },
        "message": {
          "description": "Show failure message when operation fails (omitted when operation succeeds).",
          "type": "string"
        }
      }
    },
    "ImageUrl": {
      "required": [
        "url"
      ],
      "type": "object",
      "properties": {
        "url": {
          "description": "Publicly reachable URL of an image",
          "type": "string"
        }
      }
    }
  },
  "parameters": {
    "returnFaceAttributes": {
      "in": "query",
      "name": "returnFaceAttributes",
      "description": "Analyze and return the one or more specified face attributes in the comma-separated string like \"returnFaceAttributes=age,gender\". Supported face attributes include age, gender, headPose, smile, facialHair, glasses and emotion. Note that each face attribute analysis has additional computational and time cost.",
      "required": false,
      "type": "array",
      "items": {
        "enum": [
          "age",
          "gender",
          "headPose",
          "smile",
          "facialHair",
          "glasses",
          "emotion",
          "hair",
          "makeup",
          "occlusion",
          "accessories",
          "blur",
          "exposure",
          "noise"
        ],
        "type": "string",
        "x-nullable": false,
        "x-ms-enum": {
          "name": "FaceAttributeType",
          "modelAsString": false
        }
      },
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "targetFace": {
      "in": "query",
      "name": "targetFace",
      "description": "A face rectangle to specify the target face to be added to a person in the format of \"targetFace=left,top,width,height\". E.g. \"targetFace=10,10,100,100\". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image.",
      "required": false,
      "type": "array",
      "items": {
        "format": "int32",
        "maxItems": 4,
        "minItems": 4,
        "type": "integer",
        "x-nullable": false
      },
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "faceUserData": {
      "in": "query",
      "name": "userData",
      "description": "User-specified data about the face for any purpose. The maximum length is 1KB.",
      "required": false,
      "type": "string",
      "maxLength": 1024,
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "faceListId": {
      "in": "path",
      "name": "faceListId",
      "description": "Id referencing a particular face list.",
      "required": true,
      "type": "string",
      "collectionFormat": "csv",
      "maxLength": 64,
      "pattern": "^[a-z0-9-_]+$",
      "x-ms-parameter-location": "method"
    },
    "personGroupId": {
      "in": "path",
      "name": "personGroupId",
      "description": "Id referencing a particular person group.",
      "required": true,
      "type": "string",
      "collectionFormat": "csv",
      "maxLength": 64,
      "pattern": "^[a-z0-9-_]+$",
      "x-ms-parameter-location": "method"
    },
    "largeFaceListId": {
      "in": "path",
      "name": "largeFaceListId",
      "description": "Id referencing a particular large face list.",
      "required": true,
      "type": "string",
      "collectionFormat": "csv",
      "maxLength": 64,
      "pattern": "^[a-z0-9-_]+$",
      "x-ms-parameter-location": "method"
    },
    "largePersonGroupId": {
      "in": "path",
      "name": "largePersonGroupId",
      "description": "Id referencing a particular large person group.",
      "required": true,
      "type": "string",
      "collectionFormat": "csv",
      "maxLength": 64,
      "pattern": "^[a-z0-9-_]+$",
      "x-ms-parameter-location": "method"
    },
    "personId": {
      "in": "path",
      "name": "personId",
      "description": "Id referencing a particular person.",
      "required": true,
      "type": "string",
      "format": "uuid",
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "persistedFaceId": {
      "in": "path",
      "name": "persistedFaceId",
      "description": "Id referencing a particular persistedFaceId of an existing face.",
      "required": true,
      "type": "string",
      "format": "uuid",
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "applyScope": {
      "in": "query",
      "name": "applyScope",
      "description": "User specified snapshot apply scopes as a search filter. ApplyScope is an array of the target Azure subscription ids for the snapshot, specified by the user who created the snapshot by Snapshot - Take.",
      "required": false,
      "type": "array",
      "items": {
        "format": "uuid",
        "type": "string",
        "x-nullable": false
      },
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "operationId": {
      "in": "path",
      "name": "operationId",
      "description": "Id referencing a particular take/apply snapshot operation.",
      "required": true,
      "type": "string",
      "format": "uuid",
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "snapshotId": {
      "in": "path",
      "name": "snapshotId",
      "description": "Id referencing a particular snapshot.",
      "required": true,
      "type": "string",
      "format": "uuid",
      "collectionFormat": "csv",
      "x-ms-parameter-location": "method"
    },
    "Endpoint": {
      "in": "path",
      "name": "Endpoint",
      "description": "Supported Cognitive Services endpoints (protocol and hostname, for example: https://westus.api.cognitive.microsoft.com).",
      "required": true,
      "type": "string",
      "x-ms-parameter-location": "client",
      "x-ms-skip-url-encoding": true
    },
    "recognitionModel": {
      "in": "query",
      "name": "recognitionModel",
      "description": "Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need.",
      "required": false,
      "type": "string",
      "default": "recognition_01",
      "enum": [
        "recognition_01",
        "recognition_02",
        "recognition_03"
      ],
      "x-ms-parameter-location": "method",
      "x-nullable": false,
      "x-ms-enum": {
        "name": "RecognitionModel",
        "modelAsString": true
      }
    },
    "returnRecognitionModel": {
      "in": "query",
      "name": "returnRecognitionModel",
      "description": "A value indicating whether the operation should return 'recognitionModel' in response.",
      "required": false,
      "type": "boolean",
      "default": false,
      "x-ms-parameter-location": "method"
    },
    "detectionModel": {
      "in": "query",
      "name": "detectionModel",
      "description": "Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it.",
      "required": false,
      "type": "string",
      "default": "detection_01",
      "enum": [
        "detection_01",
        "detection_02"
      ],
      "x-ms-parameter-location": "method",
      "x-nullable": false,
      "x-ms-enum": {
        "name": "DetectionModel",
        "modelAsString": true
      }
    }
  },
  "securityDefinitions": {
    "apim_key": {
      "type": "apiKey",
      "name": "Ocp-Apim-Subscription-Key",
      "in": "header"
    }
  },
  "security": [
    {
      "apim_key": []
    }
  ],
  "x-ms-parameterized-host": {
    "hostTemplate": "{Endpoint}/face/v1.0",
    "useSchemePrefix": false,
    "parameters": [
      {
        "$ref": "#/parameters/Endpoint"
      }
    ]
  },
  "x-ms-paths": {
    "/verify?overload=person": {
      "post": {
        "description": "Verify whether two faces belong to a same person. Compares a face Id with a Person Id",
        "operationId": "Face_VerifyFaceToPerson",
        "parameters": [
          {
            "name": "body",
            "description": "Request body for face to person verification.",
            "in": "body",
            "required": true,
            "x-ms-client-flatten": true,
            "schema": {
              "$ref": "#/definitions/VerifyFaceToPersonRequest"
            }
          }
        ],
        "consumes": [
          "application/json"
        ],
        "produces": [
          "application/json"
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the verification result.",
            "schema": {
              "$ref": "#/definitions/VerifyResult"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Verify face to person example": {
            "$ref": "./examples/VerifyFaceToPerson.json"
          }
        }
      }
    },
    "/detect?overload=stream": {
      "post": {
        "description": "Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.<br />\n* No image will be stored. Only the extracted face feature will be stored on server. The faceId is an identifier of the face feature and will be used in [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify), [Face - Verify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface), and [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar). The stored face feature(s) will expire and be deleted 24 hours after the original detection call.\n* Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\n* For optimal results when querying [Face - Identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify), [Face - Verify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface), and [Face - Find Similar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar) ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |\n\n* Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to [How to specify a recognition model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'recognition_01': | The default recognition model for [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl). All those faceIds created before 2019 March are bonded with this recognition model. |\n  | 'recognition_02': | Recognition model released in 2019 March. |\n  | 'recognition_03': | Recognition model released in 2020 May. 'recognition_03' is recommended since its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. |",
        "operationId": "Face_DetectWithStream",
        "parameters": [
          {
            "name": "returnFaceId",
            "in": "query",
            "description": "A value indicating whether the operation should return faceIds of detected faces.",
            "type": "boolean",
            "default": true
          },
          {
            "name": "returnFaceLandmarks",
            "in": "query",
            "description": "A value indicating whether the operation should return landmarks of the detected faces.",
            "type": "boolean",
            "default": false
          },
          {
            "$ref": "#/parameters/returnFaceAttributes"
          },
          {
            "name": "Image",
            "in": "body",
            "required": true,
            "x-ms-parameter-location": "method",
            "description": "An image stream.",
            "schema": {
              "type": "object",
              "format": "file"
            }
          },
          {
            "$ref": "#/parameters/recognitionModel"
          },
          {
            "$ref": "#/parameters/returnRecognitionModel"
          },
          {
            "$ref": "#/parameters/detectionModel"
          }
        ],
        "consumes": [
          "application/octet-stream"
        ],
        "produces": [
          "application/json"
        ],
        "responses": {
          "200": {
            "description": "A successful call returns an array of face entries ranked by face rectangle size in descending order. An empty response indicates no faces detected.",
            "schema": {
              "$ref": "#/definitions/DetectedFaces"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Detect with stream example": {
            "$ref": "./examples/DetectWithStream.json"
          }
        }
      }
    },
    "/persongroups/{personGroupId}/persons/{personId}/persistedfaces?overload=stream": {
      "post": {
        "description": "Add a face to a person into a person group for face identification or verification. To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [PersonGroup PersonFace - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/deleteface), [PersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/delete) or [PersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n*   Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n*   Each person entry can hold up to 248 faces.\n*   JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n*   \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n*   Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n*   Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [PersonGroup Person - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroupperson/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |",
        "operationId": "PersonGroupPerson_AddFaceFromStream",
        "parameters": [
          {
            "$ref": "#/parameters/personGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "name": "Image",
            "in": "body",
            "required": true,
            "x-ms-parameter-location": "method",
            "description": "An image stream.",
            "schema": {
              "type": "object",
              "format": "file"
            }
          },
          {
            "$ref": "#/parameters/detectionModel"
          }
        ],
        "produces": [
          "application/json"
        ],
        "consumes": [
          "application/octet-stream"
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Add face to person with stream example": {
            "$ref": "./examples/AddPersonGroupPersonFaceFromStream.json"
          }
        }
      }
    },
    "/facelists/{faceListId}/persistedfaces?overload=stream": {
      "post": {
        "description": "Add a face to a specified face list, up to 1,000 faces.\n<br /> To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [FaceList - Delete Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/deleteface) or [FaceList - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better detection and recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same face list are processed sequentially and to/from different face lists are in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [FaceList - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |",
        "operationId": "FaceList_AddFaceFromStream",
        "parameters": [
          {
            "$ref": "#/parameters/faceListId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "name": "Image",
            "in": "body",
            "required": true,
            "x-ms-parameter-location": "method",
            "description": "An image stream.",
            "schema": {
              "type": "object",
              "format": "file"
            }
          },
          {
            "$ref": "#/parameters/detectionModel"
          }
        ],
        "consumes": [
          "application/octet-stream"
        ],
        "produces": [
          "application/json"
        ],
        "responses": {
          "200": {
            "description": "A successful call returns a new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Add face to face list from stream example": {
            "$ref": "./examples/AddFaceListFaceFromStream.json"
          }
        }
      }
    },
    "/largepersongroups/{largePersonGroupId}/persons/{personId}/persistedfaces?overload=stream": {
      "post": {
        "description": "Add a face to a person into a large person group for face identification or verification. To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [LargePersonGroup PersonFace - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/deleteface), [LargePersonGroup Person - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/delete) or [LargePersonGroup - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* Each person entry can hold up to 248 faces.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [LargePersonGroup Person - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroupperson/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |",
        "operationId": "LargePersonGroupPerson_AddFaceFromStream",
        "parameters": [
          {
            "$ref": "#/parameters/largePersonGroupId"
          },
          {
            "$ref": "#/parameters/personId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "name": "Image",
            "in": "body",
            "required": true,
            "x-ms-parameter-location": "method",
            "description": "An image stream.",
            "schema": {
              "type": "object",
              "format": "file"
            }
          },
          {
            "$ref": "#/parameters/detectionModel"
          }
        ],
        "produces": [
          "application/json"
        ],
        "consumes": [
          "application/octet-stream"
        ],
        "responses": {
          "200": {
            "description": "A successful call returns the new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Add face to person with stream example": {
            "$ref": "./examples/AddLargePersonGroupPersonFaceFromStream.json"
          }
        }
      }
    },
    "/largefacelists/{largeFaceListId}/persistedfaces?overload=stream": {
      "post": {
        "description": "Add a face to a specified large face list, up to 1,000,000 faces.\n<br /> To deal with an image contains multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature will be stored on server until [LargeFaceList Face - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/deleteface) or [LargeFaceList - Delete](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/delete) is called.\n<br /> Note persistedFaceId is different from faceId generated by [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl).\n* Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\n* JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\n* \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from [Face - Detect](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl), there’s no guarantee to detect and add the face successfully.\n* Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\n* Adding/deleting faces to/from a same face list are processed sequentially and to/from different face lists are in parallel.\n* The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\n* Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to [How to specify a detection model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)\n  | Model | Recommended use-case(s) |\n  | ---------- | -------- |\n  | 'detection_01': | The default detection model for [LargeFaceList - Add Face](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/addfacefromurl). Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. |\n  | 'detection_02': | Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. |\n\nQuota:\n* Free-tier subscription quota: 1,000 faces per large face list.\n* S0-tier subscription quota: 1,000,000 faces per large face list.",
        "operationId": "LargeFaceList_AddFaceFromStream",
        "parameters": [
          {
            "$ref": "#/parameters/largeFaceListId"
          },
          {
            "$ref": "#/parameters/faceUserData"
          },
          {
            "$ref": "#/parameters/targetFace"
          },
          {
            "name": "Image",
            "in": "body",
            "required": true,
            "x-ms-parameter-location": "method",
            "description": "An image stream.",
            "schema": {
              "type": "object",
              "format": "file"
            }
          },
          {
            "$ref": "#/parameters/detectionModel"
          }
        ],
        "consumes": [
          "application/octet-stream"
        ],
        "produces": [
          "application/json"
        ],
        "responses": {
          "200": {
            "description": "A successful call returns a new persistedFaceId.",
            "schema": {
              "$ref": "#/definitions/PersistedFace"
            }
          },
          "default": {
            "description": "Error response.",
            "schema": {
              "$ref": "#/definitions/APIError"
            }
          }
        },
        "x-ms-examples": {
          "Add face to large face list from stream example": {
            "$ref": "./examples/AddLargeFaceListFaceFromStream.json"
          }
        }
      }
    }
  }
}
